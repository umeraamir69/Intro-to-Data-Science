{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMqnMVkjBcOSG373BciwhmP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Date: 26/11/2023\n","# CSC461 – Assignment3 – Machine Learning\n","# FA21-BSE-114\n","# Umer Amir"],"metadata":{"id":"x0Uj_wDV8cmJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Question 1**"],"metadata":{"id":"AsD6eQ0147NQ"}},{"cell_type":"markdown","source":["Q1: Provide responses to the following questions about the dataset.\n","1.\tHow many instances does the dataset contain?\n","Ans: 110 instances\n","2.\tHow many input attributes does the dataset contain?\n","Ans: 7 input instances. Height, weight, beard, hair length, shoe size, scarf, and eye color.\n","3.\tHow many possible values does the output attribute have?\n","Ans: There is only one output attribute gender that has two output values male and female.\n","4.\tHow many input attributes are categorical?\n","Ans: Beard, hair length, scarf, and eye color are the input attributes that are categorical.\n","5.\tWhat is the dataset's class ratio (male vs female)?\n","Ans: 62 were males and 48 were females."],"metadata":{"id":"uGcbIdJ-43dK"}},{"cell_type":"markdown","source":["**Question 2**"],"metadata":{"id":"8P_tJpiQ4_vZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SvxLRRTVpLjD"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, cross_val_predict\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.preprocessing import LabelEncoder\n","\n","df = pd.read_csv('gender-prediction.csv')\n","\n","# Preprocess the data\n","le = LabelEncoder()\n","df['beard'] = le.fit_transform(df['beard'])\n","df['hair_length'] = le.fit_transform(df['hair_length'])\n","df['scarf'] = le.fit_transform(df['scarf'])\n","df['eye_color'] = le.fit_transform(df['eye_color'])\n","df['gender'] = le.fit_transform(df['gender'])\n","\n","# Define features (X) and target variable (y)\n","X = df.drop('gender', axis=1)\n","y = df['gender']\n","\n","# Question 1: Train/test split ratio of 2/3\n","X_train_2_3, X_test_2_3, y_train_2_3, y_test_2_3 = train_test_split(X, y, test_size=1/3, random_state=42)\n","\n","# Models\n","models = {\n","    'Logistic Regression': LogisticRegression(),\n","    'Support Vector Machine': SVC(),\n","    'Multilayer Perceptron': MLPClassifier()\n","}\n","\n","# Results dictionary\n","results = {}\n","\n","# Train and evaluate models\n","for model_name, model in models.items():\n","    # Cross-validation prediction for getting incorrect classifications\n","    y_pred_cv = cross_val_predict(model, X_train_2_3, y_train_2_3, cv=3)\n","    incorrect_instances = np.sum(y_pred_cv != y_train_2_3)\n","    results[model_name] = {'Incorrectly Classified Instances': incorrect_instances}\n","\n","# Print results for Question 1\n","for model_name, result in results.items():\n","    print(f\"{model_name}: {result['Incorrectly Classified Instances']} instances incorrectly classified.\")\n","\n","# Question 2: Rerun with 80/20 train/test split\n","X_train_4_5, X_test_4_5, y_train_4_5, y_test_4_5 = train_test_split(X, y, test_size=1/5, random_state=42)\n","results_80_20 = {}\n","\n","for model_name, model in models.items():\n","    model.fit(X_train_4_5, y_train_4_5)\n","    y_pred_test = model.predict(X_test_4_5)\n","    incorrect_instances = np.sum(y_pred_test != y_test_4_5)\n","    results_80_20[model_name] = {'Incorrectly Classified Instances': incorrect_instances}\n","\n","# Print results for Question 2\n","print(\"\\nResults with 80/20 train/test split:\")\n","for model_name, result in results_80_20.items():\n","    print(f\"{model_name}: {result['Incorrectly Classified Instances']} instances incorrectly classified.\")\n","\n","# Question 3: Identify 2 most \"powerful\" attributes\n","# You can use feature importance, coefficients, or any other method depending on the model\n","# In this example, Logistic Regression is used to get feature importance\n","lr_model = LogisticRegression()\n","lr_model.fit(X_train_4_5, y_train_4_5)\n","feature_importance = lr_model.coef_[0]\n","top_attributes_indices = np.argsort(np.abs(feature_importance))[::-1][:2]\n","top_attributes = X.columns[top_attributes_indices]\n","\n","print(f\"\\nTop 2 most 'powerful' attributes: {top_attributes[0]} and {top_attributes[1]}\")\n","\n","# Question 4: Exclude top 2 attributes and rerun with 80/20 split\n","X_excluded = X.drop(top_attributes, axis=1)\n","X_train_excluded, X_test_excluded, y_train_excluded, y_test_excluded = train_test_split(X_excluded, y, test_size=1/5, random_state=42)\n","\n","results_excluded = {}\n","\n","for model_name, model in models.items():\n","    model.fit(X_train_excluded, y_train_excluded)\n","    y_pred_test_excluded = model.predict(X_test_excluded)\n","    incorrect_instances = np.sum(y_pred_test_excluded != y_test_excluded)\n","    results_excluded[model_name] = {'Incorrectly Classified Instances': incorrect_instances}\n","\n","# Print results for Question 4\n","print(\"\\nResults after excluding top 2 attributes:\")\n","for model_name, result in results_excluded.items():\n","    print(f\"{model_name}: {result['Incorrectly Classified Instances']} instances incorrectly classified.\")\n"]},{"cell_type":"markdown","source":["**Question 3**"],"metadata":{"id":"orqK_VQr5Ci2"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import f1_score\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Load your dataset\n","# Replace 'your_dataset.csv' with the actual path to your dataset\n","# Assuming the dataset has columns like 'height', 'weight', 'beard', 'hair_length', 'shoe_size', 'scarf', 'eye_color', 'gender'\n","df = pd.read_csv('gender-prediction.csv')\n","\n","# Preprocess the data\n","le = LabelEncoder()\n","df['beard'] = le.fit_transform(df['beard'])\n","df['hair_length'] = le.fit_transform(df['hair_length'])\n","df['scarf'] = le.fit_transform(df['scarf'])\n","df['eye_color'] = le.fit_transform(df['eye_color'])\n","df['gender'] = le.fit_transform(df['gender'])\n","# Load your gender prediction dataset\n","# Replace 'your_dataset.csv' with the actual path to your dataset\n","# Assuming the dataset has columns like 'height', 'weight', 'beard', 'hair_length', 'shoe_size', 'scarf', 'eye_color', 'gender'\n","\n","# Preprocess the data if needed\n","# Example: Encode categorical variables, handle missing values\n","\n","# Define features (X) and target variable (y)\n","X = df.drop('gender', axis=1)\n","y = df['gender']\n","\n","# Random Forest classifier\n","rf_classifier = RandomForestClassifier(random_state=42)\n","\n","# Monte Carlo Cross-Validation\n","monte_carlo_f1_scores = []\n","iterations = 100\n","\n","for _ in range(iterations):\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    rf_classifier.fit(X_train, y_train)\n","    y_pred = rf_classifier.predict(X_test)\n","    monte_carlo_f1_scores.append(f1_score(y_test, y_pred, average='binary'))\n","\n","monte_carlo_avg_f1 = np.mean(monte_carlo_f1_scores)\n","\n","# Leave P-Out Cross-Validation\n","leave_p_out_f1_scores = []\n","p_out = 5  # You can adjust the number of folds as needed\n","\n","fold = StratifiedKFold(n_splits=p_out, shuffle=True, random_state=42)\n","\n","for train, test in fold.split(X, y):\n","    X_train, X_test = X.iloc[train], X.iloc[test]\n","    y_train, y_test = y.iloc[train], y.iloc[test]\n","    rf_classifier.fit(X_train, y_train)\n","    y_pred = rf_classifier.predict(X_test)\n","    leave_p_out_f1_scores.append(f1_score(y_test, y_pred, average='binary'))\n","\n","leave_p_out_avg_f1 = np.mean(leave_p_out_f1_scores)\n","\n","# Print F1 scores\n","print(f'Monte Carlo Cross-Validation F1 Score: {monte_carlo_avg_f1:.4f}')\n","print(f'Leave P-Out Cross-Validation F1 Score: {leave_p_out_avg_f1:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTwySmiwp8W1","executionInfo":{"status":"ok","timestamp":1701022987546,"user_tz":-300,"elapsed":17958,"user":{"displayName":"USAMA TUFAIL","userId":"02791947146436024953"}},"outputId":"810b610a-2580-4330-a698-4db253772478"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Monte Carlo Cross-Validation F1 Score: 0.9524\n","Leave P-Out Cross-Validation F1 Score: 0.9759\n"]}]},{"cell_type":"markdown","source":["**Question 4**"],"metadata":{"id":"BsfpsAKG5ExD"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Load your dataset\n","# Replace 'your_dataset.csv' with the actual path to your dataset\n","# Assuming the dataset has columns like 'height', 'weight', 'beard', 'hair_length', 'shoe_size', 'scarf', 'eye_color', 'gender'\n","df = pd.read_csv('gender-prediction.csv')\n","\n","# Preprocess the data\n","le = LabelEncoder()\n","df['beard'] = le.fit_transform(df['beard'])\n","df['hair_length'] = le.fit_transform(df['hair_length'])\n","df['scarf'] = le.fit_transform(df['scarf'])\n","df['eye_color'] = le.fit_transform(df['eye_color'])\n","df['gender'] = le.fit_transform(df['gender'])\n","# Load the gender prediction dataset\n","# Replace 'your_dataset.csv' with the actual path to your dataset\n","# Assuming the dataset has columns like 'height', 'weight', 'beard', 'hair_length', 'shoe_size', 'scarf', 'eye_color', 'gender'\n","\n","# Preprocess the data if needed\n","# Example: Encode categorical variables, handle missing values\n","\n","# Define features (X) and target variable (y)\n","X = df.drop('gender', axis=1)\n","y = df['gender']\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train the Gaussian Naïve Bayes classifier\n","nb_classifier = GaussianNB()\n","nb_classifier.fit(X_train, y_train)\n","\n","# Load the test dataset\n","# Replace 'test_dataset.csv' with the actual path to your test dataset\n","test_df = pd.read_csv('test.csv')\n","\n","# Preprocess the test data if needed\n","# Example: Encode categorical variables, handle missing values\n","test_df['beard'] = le.fit_transform(test_df['beard'])\n","test_df['hair_length'] = le.fit_transform(test_df['hair_length'])\n","test_df['scarf'] = le.fit_transform(test_df['scarf'])\n","test_df['eye_color'] = le.fit_transform(test_df['eye_color'])\n","test_df['gender'] = le.fit_transform(test_df['gender'])\n","# Define features (X_test) and target variable (y_test)\n","X_test = test_df.drop('gender', axis=1)\n","y_test = test_df['gender']\n","\n","# Make predictions on the test set\n","y_pred = nb_classifier.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='binary')\n","recall = recall_score(y_test, y_pred, average='binary')\n","\n","# Report the results\n","print(f'Accuracy: {accuracy:.4f}')\n","print(f'Precision: {precision:.4f}')\n","print(f'Recall: {recall:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kmseXcKl25Eo","executionInfo":{"status":"ok","timestamp":1701023735863,"user_tz":-300,"elapsed":534,"user":{"displayName":"USAMA TUFAIL","userId":"02791947146436024953"}},"outputId":"a1434336-825e-4c9e-fb55-ebcd66eb92d4"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.0000\n","Precision: 1.0000\n","Recall: 1.0000\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"sbB5NnIk6KrP"},"execution_count":null,"outputs":[]}]}